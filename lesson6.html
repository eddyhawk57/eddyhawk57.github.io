<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Lesson 6 - Improving Model Performance</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #333;
    }

    header {
      background-color: #2e7d32;
      color: white;
      padding: 20px;
      text-align: center;
    }

    main {
      padding: 20px;
      max-width: 900px;
      margin: auto;
      background: white;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
      border-radius: 8px;
    }

    h1 {
      color: #2e7d32;
    }

    h2 {
      margin-top: 30px;
      color: #444;
    }

    p {
      line-height: 1.7;
      margin-bottom: 15px;
    }

    ul {
      margin: 10px 0 20px 20px;
    }

    pre {
      background: #eee;
      padding: 10px;
      border-radius: 5px;
      overflow-x: auto;
    }

    footer {
      background-color: #333;
      color: white;
      text-align: center;
      padding: 20px;
      margin-top: 40px;
    }

    .footer-ad {
      margin-bottom: 10px;
    }

    .nav-links {
      display: flex;
      justify-content: space-between;
      margin-top: 30px;
    }

    .nav-links a {
      color: #2e7d32;
      text-decoration: none;
      font-weight: bold;
    }

    .nav-links a:hover {
      text-decoration: underline;
    }
  </style>
</head>
<body>

  <header>
    <h1>Lesson 6: Improving Model Performance</h1>
  </header>

  <main>
    <h2>Introduction</h2>
    <p>
      After evaluating a model, the next step is to improve its performance. This involves optimizing features, tuning algorithms, and reducing errors.
    </p>

    <h2>Key Techniques</h2>
    <ul>
      <li><strong>Feature Engineering:</strong> Creating better inputs (e.g., extracting text length, combining attributes).</li>
      <li><strong>Hyperparameter Tuning:</strong> Adjusting model settings (e.g., learning rate, depth, regularization).</li>
      <li><strong>Cross-Validation:</strong> Testing model on multiple folds of the dataset for better reliability.</li>
      <li><strong>Ensemble Methods:</strong> Combining multiple models (e.g., random forest, gradient boosting).</li>
      <li><strong>Scaling & Normalization:</strong> Ensuring features have the same range.</li>
    </ul>

    <h2>Grid Search Example (Scikit-Learn)</h2>
    <pre><code>
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

params = {'n_estimators': [50, 100], 'max_depth': [4, 6, 8]}
model = RandomForestClassifier()
grid = GridSearchCV(model, params, cv=5)
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)
    </code></pre>

    <h2>Practical Tips</h2>
    <ul>
      <li>Use domain knowledge to craft features.</li>
      <li>Don’t overfit: use techniques like dropout or regularization.</li>
      <li>Balance the dataset if it's skewed using resampling.</li>
    </ul>

    <h2>Conclusion</h2>
    <p>
      Improving model performance is an iterative process. Always test changes using evaluation metrics to avoid overfitting. In the next lesson, we’ll explore how deep learning takes things to the next level.
    </p>

    <div class="nav-links">
      <a href="lesson5.html">&larr; Back to Lesson 5</a>
      <a href="lesson7.html">Next Lesson &rarr;</a>
    </div>
  </main>

  <footer>
    <div class="footer-ad">
      <!-- Your Ad Code Goes Here -->
      <p>Advertisement Space</p>
    </div>
    <p>&copy; 2025 YourSiteName. All rights reserved.</p>
  </footer>

</body>
</html>
